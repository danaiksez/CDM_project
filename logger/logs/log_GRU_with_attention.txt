GRU and augmented attention and baseline model etc.
   epoch          : 1
    loss           : 0.4995813805123602
    accuracy       : 0.839649347961463
    precision_0    : 0.8504470131511382
    precision_1    : 0.0
    precision_2    : 0.21739130434782608
    precision_3    : 0
    precision_4    : 0.5876225330900362
    precision_5    : 0.27956989247311825
    precision_6    : 0.5968013468013468
    recall_0       : 0.9277035008003248
    recall_1       : 0.0
    recall_2       : 0.11231884057971013
    recall_3       : 0
    recall_4       : 0.4679399251042216
    recall_5       : 0.23010752688172043
    recall_6       : 0.5061447811447811
    f1_0           : 0.8741468016397196
    f1_1           : 0.0
    f1_2           : 0.14057971014492754
    f1_3           : 0
    f1_4           : 0.4792524520432923
    f1_5           : 0.2409114183307732
    f1_6           : 0.5320226070226072
    val_loss       : 0.48163051095515075
    val_accuracy   : 0.846735661581746
    val_precision_0: 0.8715305835791809
    val_precision_1: 1.0
    val_precision_2: 0
    val_precision_3: 0
    val_precision_4: 0.5585008049021137
    val_precision_5: 0
    val_precision_6: 0.387283950617284
    val_recall_0   : 0.9089688077957855
    val_recall_1   : 1.0
    val_recall_2   : 0
    val_recall_3   : 0
    val_recall_4   : 0.4725955932471745
    val_recall_5   : 0
    val_recall_6   : 0.403395061728395
    val_f1_0       : 0.8772223066190223
    val_f1_1       : 1.0
    val_f1_2       : 0
    val_f1_3       : 0
    val_f1_4       : 0.47991172583578745
    val_f1_5       : 0
    val_f1_6       : 0.3843062904174016

epoch 2
Train Epoch: 2 [8000/8895 (90%)] Loss: 0.152731
    epoch          : 2
    loss           : 0.4292640111227863
    accuracy       : 0.8542084447189773
    precision_0    : 0.863678821464854
    precision_1    : 0.35185185185185186
    precision_2    : 0.34967320261437906
    precision_3    : 1.0
    precision_4    : 0.6291792588244424
    precision_5    : 0.30503144654088055
    precision_6    : 0.6378651685393256
    recall_0       : 0.9272244915674892
    recall_1       : 0.2037037037037037
    recall_2       : 0.2326797385620915
    recall_3       : 1.0
    recall_4       : 0.5192044432742966
    recall_5       : 0.2654088050314465
    recall_6       : 0.5886516853932585
    f1_0           : 0.8821324003050788
    f1_1           : 0.2336860670194003
    f1_2           : 0.2568627450980392
    f1_3           : 1.0
    f1_4           : 0.5285333186374539
    f1_5           : 0.27190026954177904
    f1_6           : 0.5947957909755657
    val_loss       : 0.4915353826188922
    val_accuracy   : 0.8364477156149775
    val_precision_0: 0.8350341382183183
    val_precision_1: 0
    val_precision_2: 0
    val_precision_3: 0
    val_precision_4: 0.7644389438943895
    val_precision_5: 0.2857142857142857
    val_precision_6: 0.5561224489795918
    val_recall_0   : 0.9545265603044993
    val_recall_1   : 0
    val_recall_2   : 0
    val_recall_3   : 0
    val_recall_4   : 0.3996880319900124
    val_recall_5   : 0.21428571428571427
    val_recall_6   : 0.5263605442176871
    val_f1_0       : 0.8783848076410293
    val_f1_1       : 0
    val_f1_2       : 0
    val_f1_3       : 0
    val_f1_4       : 0.481436423377309
    val_f1_5       : 0.23809523809523808
    val_f1_6       : 0.5305150631681242

Epoch 3
    epoch          : 3
    loss           : 0.37771492028669645
    accuracy       : 0.8688405545756118
    precision_0    : 0.8754057774250164
    precision_1    : 0.48481012658227846
    precision_2    : 0.5022222222222222
    precision_3    : 0.4090909090909091
    precision_4    : 0.6658737494838458
    precision_5    : 0.44261477045908176
    precision_6    : 0.6569872958257714
    recall_0       : 0.9289326046052254
    recall_1       : 0.3917721518987342
    recall_2       : 0.38888888888888884
    recall_3       : 0.3484848484848485
    recall_4       : 0.5721907623691762
    recall_5       : 0.3788423153692615
    recall_6       : 0.6148517846339987
    f1_0           : 0.8897823013884547
    f1_1           : 0.4037673297166968
    f1_2           : 0.4186666666666667
    f1_3           : 0.36363636363636365
    f1_4           : 0.5775639958478545
    f1_5           : 0.3973481608212147
    f1_6           : 0.6202028058652382
    val_loss       : 0.4769745908277063
    val_accuracy   : 0.8458199974894416
    val_precision_0: 0.8511296984965048
    val_precision_1: 0
    val_precision_2: 0
    val_precision_3: 0
    val_precision_4: 0.6251439263097296
    val_precision_5: 0
    val_precision_6: 0.5045454545454545
    val_recall_0   : 0.9359837680304832
    val_recall_1   : 0
    val_recall_2   : 0
    val_recall_3   : 0
    val_recall_4   : 0.4498750649657384
    val_recall_5   : 0
    val_recall_6   : 0.478030303030303
    val_f1_0       : 0.8791423642237471
    val_f1_1       : 0
    val_f1_2       : 0
    val_f1_3       : 0
    val_f1_4       : 0.4839627774179179
    val_f1_5       : 0
    val_f1_6       : 0.4797402597402597

epoch 4
   epoch          : 4
    loss           : 0.3243724547587469
    accuracy       : 0.8839728259884349
    precision_0    : 0.8871380168528084
    precision_1    : 0.6351895579168306
    precision_2    : 0.6638888888888889
    precision_3    : 0.575
    precision_4    : 0.6925141035167297
    precision_5    : 0.523936170212766
    precision_6    : 0.7076606260296542
    recall_0       : 0.9328552370140373
    recall_1       : 0.5231404958677686
    recall_2       : 0.5648809523809524
    recall_3       : 0.5006613756613757
    recall_4       : 0.6149550883059249
    recall_5       : 0.46198581560283686
    recall_6       : 0.6714717188358047
    f1_0           : 0.8997394282427621
    f1_1           : 0.5376289458934085
    f1_2           : 0.5806405895691608
    f1_3           : 0.5148148148148147
    f1_4           : 0.6175148125048907
    f1_5           : 0.47496531836957384
    f1_6           : 0.6743482126513438
    val_loss       : 0.48484916343226747
    val_accuracy   : 0.8466935909544053
    val_precision_0: 0.8613522193863555
    val_precision_1: 0
    val_precision_2: 1.0
    val_precision_3: 0
    val_precision_4: 0.5787918309574361
    val_precision_5: 0.2727272727272727
    val_precision_6: 0.55359477124183
    val_recall_0   : 0.9268041956613907
    val_recall_1   : 0
    val_recall_2   : 0.5
    val_recall_3   : 0
    val_recall_4   : 0.455658274846173
    val_recall_5   : 0.16666666666666666
    val_recall_6   : 0.5400326797385621
    val_f1_0       : 0.8796736898165893
    val_f1_1       : 0
    val_f1_2       : 0.6666666666666666
    val_f1_3       : 0
    val_f1_4       : 0.47546589087152347
    val_f1_5       : 0.19696969696969696
    val_f1_6       : 0.5363990040460629

Epoch   epoch          : 5
    loss           : 0.27454502607641673
    accuracy       : 0.9027842738516587
    precision_0    : 0.9044690530604456
    precision_1    : 0.6485676716445947
    precision_2    : 0.7131410256410255
    precision_3    : 0.665954415954416
    precision_4    : 0.7340284021754895
    precision_5    : 0.6367431972789116
    precision_6    : 0.7532802701398942
    recall_0       : 0.9399679461000274
    recall_1       : 0.5626232741617356
    recall_2       : 0.6166666666666667
    recall_3       : 0.5195105820105819
    recall_4       : 0.6661451031099608
    recall_5       : 0.5877380952380952
    recall_6       : 0.7245055475156778
    f1_0           : 0.9136046313239157
    f1_1           : 0.5699650119768462
    f1_2           : 0.6375305250305249
    f1_3           : 0.5553558460421205
    f1_4           : 0.6669459936890625
    f1_5           : 0.5936020923520923
    f1_6           : 0.7249982771690452
    val_loss       : 0.5520676095213564
    val_accuracy   : 0.8231888866994769
    val_precision_0: 0.8705533017937149
    val_precision_1: 0
    val_precision_2: 1.0
    val_precision_3: 0.0
    val_precision_4: 0.4721182655135687
    val_precision_5: 0.0
    val_precision_6: 0.51010101010101
    val_recall_0   : 0.8888640614589932
    val_recall_1   : 0
    val_recall_2   : 0.5
    val_recall_3   : 0.0
    val_recall_4   : 0.4433469186282294
    val_recall_5   : 0.0
    val_recall_6   : 0.48989898989898994
    val_f1_0       : 0.8629249083123913
    val_f1_1       : 0
    val_f1_2       : 0.6666666666666666
    val_f1_3       : 0.0
    val_f1_4       : 0.41971679612062135
    val_f1_5       : 0.0
    val_f1_6       : 0.4877825877825877

Epoch 6
 epoch          : 6
    loss           : 0.2331573581552439
    accuracy       : 0.9155852779162162
    precision_0    : 0.9180369528401443
    precision_1    : 0.7168834887907055
    precision_2    : 0.7358630952380951
    precision_3    : 0.69808362369338
    precision_4    : 0.7672474897498607
    precision_5    : 0.7000000000000001
    precision_6    : 0.7610810810810809
    recall_0       : 0.9462460365117112
    recall_1       : 0.6187285223367698
    recall_2       : 0.634375
    recall_3       : 0.667828106852497
    recall_4       : 0.7135716794059579
    recall_5       : 0.6458456973293769
    recall_6       : 0.7401351351351352
    f1_0           : 0.9246698856176688
    f1_1           : 0.6324842683090108
    f1_2           : 0.6549178004535147
    f1_3           : 0.6710793271768881
    f1_4           : 0.7120070779941917
    f1_5           : 0.652440899028436
    f1_6           : 0.7379806754806761
    val_loss       : 0.5360226889434796
    val_accuracy   : 0.833131566034679
    val_precision_0: 0.8693564747717267
    val_precision_1: 0.375
    val_precision_2: 0.0
    val_precision_3: 0
    val_precision_4: 0.5097587371977617
    val_precision_5: 0.2807017543859649
    val_precision_6: 0.4818791946308725
    val_recall_0   : 0.902038955267104
    val_recall_1   : 0.22916666666666666
    val_recall_2   : 0.0
    val_recall_3   : 0
    val_recall_4   : 0.4443512372697516
    val_recall_5   : 0.20175438596491227
    val_recall_6   : 0.4776286353467562
    val_f1_0       : 0.8698743243311371
    val_f1_1       : 0.2708333333333333
    val_f1_2       : 0.0
    val_f1_3       : 0
    val_f1_4       : 0.43604494191846827
    val_f1_5       : 0.21052631578947367
    val_f1_6       : 0.4724086502609992

Epoch 7
epoch          : 7
    loss           : 0.200608145386751
    accuracy       : 0.9293720152402035
    precision_0    : 0.9317001164281287
    precision_1    : 0.7544031311154599
    precision_2    : 0.8310298102981029
    precision_3    : 0.7858156028368793
    precision_4    : 0.7996953810333547
    precision_5    : 0.7470759125931539
    precision_6    : 0.8006641760066417
    recall_0       : 0.952721667709129
    recall_1       : 0.6790715372907152
    recall_2       : 0.7470189701897019
    recall_3       : 0.7011144883485309
    recall_4       : 0.7525457452434282
    recall_5       : 0.7058355437665783
    recall_6       : 0.7656081361560814
    f1_0           : 0.9360932777977704
    f1_1           : 0.6885787534457966
    f1_2           : 0.7651567944250872
    f1_3           : 0.7112293144208037
    f1_4           : 0.7524045477780793
    f1_5           : 0.7086136086136087
    f1_6           : 0.7705202712052025
    val_loss       : 0.5929444241729588
    val_accuracy   : 0.8376408523946202
    val_precision_0: 0.8609655073508626
    val_precision_1: 0.3333333333333333
    val_precision_2: 0
    val_precision_3: 0.0
    val_precision_4: 0.5386012353659414
    val_precision_5: 0.25
    val_precision_6: 0.5132791327913279
    val_recall_0   : 0.9154957193799955
    val_recall_1   : 0.1111111111111111
    val_recall_2   : 0
    val_recall_3   : 0.0
    val_recall_4   : 0.4530217875806109
    val_recall_5   : 0.5
    val_recall_6   : 0.5040650406504066
    val_f1_0       : 0.8725213126697474
    val_f1_1       : 0.16666666666666666
    val_f1_2       : 0
    val_f1_3       : 0.0
    val_f1_4       : 0.45068271843387436
    val_f1_5       : 0.3333333333333333
    val_f1_6       : 0.4974706413730803

Epoch 8 
    epoch          : 8
    loss           : 0.17907505754438618
    accuracy       : 0.9364143862652919
    precision_0    : 0.9400392344741325
    precision_1    : 0.7948511904761905
    precision_2    : 0.8077777777777778
    precision_3    : 0.8216666666666668
    precision_4    : 0.8123150348058822
    precision_5    : 0.8159396825396826
    precision_6    : 0.8250496622963847
    recall_0       : 0.9572764863465552
    recall_1       : 0.7337500000000002
    recall_2       : 0.7629166666666667
    recall_3       : 0.7430952380952381
    recall_4       : 0.7717225297293394
    recall_5       : 0.7761777777777776
    recall_6       : 0.8097735399284862
    f1_0           : 0.9433376832496
    f1_1           : 0.7379526029526028
    f1_2           : 0.76744708994709
    f1_3           : 0.7576406926406924
    f1_4           : 0.7700328904130622
    f1_5           : 0.7804491656491659
    f1_6           : 0.8057442292841576
    val_loss       : 0.6339415165303455
    val_accuracy   : 0.8352284773971821
    val_precision_0: 0.8663035393524386
    val_precision_1: 0.0
    val_precision_2: 0.5
    val_precision_3: 0.0
    val_precision_4: 0.5230338540000937
    val_precision_5: 0.30303030303030304
    val_precision_6: 0.4679012345679012
    val_recall_0   : 0.9088128894448542
    val_recall_1   : 0.0
    val_recall_2   : 0.25
    val_recall_3   : 0.0
    val_recall_4   : 0.4462854649554302
    val_recall_5   : 0.2803030303030303
    val_recall_6   : 0.4717078189300411
    val_f1_0       : 0.8721805092786498
    val_f1_1       : 0.0
    val_f1_2       : 0.3333333333333333
    val_f1_3       : 0.0
    val_f1_4       : 0.44417278868642546
    val_f1_5       : 0.2727272727272727
    val_f1_6       : 0.45857338820301774
Saving checkpoint: saved/models/Mnist_Le

Epoch 9
  epoch          : 9
    loss           : 0.15786737958964384
    accuracy       : 0.9442697476102974
    precision_0    : 0.947889200127883
    precision_1    : 0.8058458402816377
    precision_2    : 0.7827380952380953
    precision_3    : 0.8465844671201814
    precision_4    : 0.837344773230048
    precision_5    : 0.8153284671532848
    precision_6    : 0.8399844418514195
    recall_0       : 0.962221456736783
    recall_1       : 0.7511024643320363
    recall_2       : 0.7283333333333334
    recall_3       : 0.7899659863945578
    recall_4       : 0.8053805193936178
    recall_5       : 0.7843065693430656
    recall_6       : 0.8290937378451965
    f1_0           : 0.950281516250967
    f1_1           : 0.7559877649371811
    f1_2           : 0.7355668934240364
    f1_3           : 0.8000422196850767
    f1_4           : 0.8007709696413756
    f1_5           : 0.7844275216537994
    f1_6           : 0.8238271193347032
    val_loss       : 0.6439511884222175
    val_accuracy   : 0.8344793235618833
    val_precision_0: 0.8637708089045603
    val_precision_1: 0.2222222222222222
    val_precision_2: 0.0
    val_precision_3: 0.0
    val_precision_4: 0.5343702902036235
    val_precision_5: 0.24404761904761904
    val_precision_6: 0.3593669250645995
    val_recall_0   : 0.906515921108229
    val_recall_1   : 0.06481481481481481
    val_recall_2   : 0.0
    val_recall_3   : 0.0
    val_recall_4   : 0.445157911361615
    val_recall_5   : 0.22321428571428573
    val_recall_6   : 0.3821059431524548
    val_f1_0       : 0.8702855803956763
    val_f1_1       : 0.1
    val_f1_2       : 0.0
    val_f1_3       : 0.0
    val_f1_4       : 0.44700803130541733
    val_f1_5       : 0.22448979591836735
    val_f1_6       : 0.35927771625446053

+------------------+------------+
|     Modules      | Parameters |
+------------------+------------+
| gru.weight_ih_l0 |   270000   |
| gru.weight_hh_l0 |   270000   |
|  gru.bias_ih_l0  |    900     |
|  gru.bias_hh_l0  |    900     |
|  output.weight   |    2100    |
|   output.bias    |     7      |
|   word.weight    |   90000    |
|    word.bias     |    300     |
|  context.weight  |    300     |
634507




